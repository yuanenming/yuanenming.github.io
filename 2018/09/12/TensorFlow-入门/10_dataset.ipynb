{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load your data or create your data in here\n",
    "npx = np.random.uniform(-1, 1, (1000, 1))                           # x data\n",
    "npy = np.power(npx, 2) + np.random.normal(0, 0.1, size=npx.shape)   # y data\n",
    "npx_train, npx_test = np.split(npx, [800])                          # training and test data\n",
    "npy_train, npy_test = np.split(npy, [800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use placeholder, later you may need different data, pass the different data into placeholder\n",
    "tfx = tf.placeholder(npx_train.dtype, npx_train.shape)\n",
    "tfy = tf.placeholder(npy_train.dtype, npy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bdf1f74447db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# choose data randomly from this buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# batch size you will use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# repeat for 3 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tfx, tfy))\n",
    "dataset = dataset.shuffle(buffer_size=1000)   # choose data randomly from this buffer\n",
    "dataset = dataset.batch(32)                   # batch size you will use\n",
    "dataset = dataset.repeat(3)                   # repeat for 3 epochs\n",
    "iterator = dataset.make_initializable_iterator()  # later we have to initialize this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your network\n",
    "bx, by = iterator.get_next()                  # use batch to update\n",
    "l1 = tf.layers.dense(bx, 10, tf.nn.relu)\n",
    "out = tf.layers.dense(l1, npy.shape[1])\n",
    "loss = tf.losses.mean_squared_error(by, out)\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# need to initialize the iterator in this case\n",
    "sess.run([iterator.initializer, tf.global_variables_initializer()], feed_dict={tfx: npx_train, tfy: npy_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(201):\n",
    "  try:\n",
    "    _, trainl = sess.run([train, loss])                       # train\n",
    "    if step % 10 == 0:\n",
    "      testl = sess.run(loss, {bx: npx_test, by: npy_test})    # test\n",
    "      print('step: %i/200' % step, '|train loss:', trainl, '|test loss:', testl)\n",
    "  except tf.errors.OutOfRangeError:     # if training takes more than 3 epochs, training will be stopped\n",
    "    print('Finish the last epoch.')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
